{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 95-865 Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your name: Ruixin Huang\n",
    "\n",
    "Your Andrew ID: ruixinh\n",
    "\n",
    "Collaborators (if none, say \\\"none\\\"; do *not* leave this blank): none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Email spam classification [45 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Get the data from: http://www.andrew.cmu.edu/user/georgech/preprocessed-enron-email-dataset.zip\n",
    "   - Unzip this into the same folder as this notebook, rename it to `email-data`\n",
    "   - The folder contains 3 subfolders:\n",
    "      - `ham` contains ham emails.\n",
    "      - `spam` contains spam emails.\n",
    "      - `testing` is a folder containing test emails for your classifier. The ham/spam label is in the filename.\n",
    "      \n",
    "**Important**: For this problem, do *not* use neural nets/deep nets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the number of ham and spam emails [1 point]\n",
    " \n",
    "In addition to providing the code, respond to the following questions:\n",
    "\n",
    "   - Is this dataset imbalanced? Will this be problematic in training the model?\n",
    "   - If so, how would you address it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of emails in ham:  1500\n",
      "the number of emails in spam:  3671\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "import glob\n",
    "sumHamDocs = 0\n",
    "sumSpamDocs = 0\n",
    "for i in glob.glob('./email-data/ham/*.txt'):\n",
    "    sumHamDocs += 1\n",
    "for i in glob.glob('./email-data/spam/*.txt'):\n",
    "    sumSpamDocs += 1\n",
    "print(\"the number of emails in ham: \",sumHamDocs)\n",
    "print(\"the number of emails in spam: \",sumSpamDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the documents [4 points]\n",
    " \n",
    "   - Provided below is a function that returns a document present in a file given a fileName.\n",
    "   - The function performs some preprocessing to (1) remove punctuation, (2),(3) remove whitespace and (4) lowercase all words.\n",
    "   - Use this function to construct a list of documents.\n",
    "   - Also construct a list of document labels containing `1` for spam and `0` for ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import codecs\n",
    "\n",
    "def makeWordList(path):\n",
    "    \n",
    "    with codecs.open(path, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        corpus_text = f.read()\n",
    "\n",
    "    for c in string.punctuation:\n",
    "        corpus_text = corpus_text.replace(c, \"\")  # -- (1)\n",
    "    \n",
    "    text = re.sub(r'\\S*\\d\\S*','',corpus_text) # -- (2)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)         # -- (3)\n",
    "    \n",
    "    text = text.lower().split()           # -- (4)         \n",
    "    \n",
    "    li = []\n",
    "    for token in text:\n",
    "        li.append(token)\n",
    "\n",
    "    return \" \".join(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "import numpy as np\n",
    "import glob\n",
    "doc = []\n",
    "index = []\n",
    "for f in glob.glob('./email-data/ham/*.txt'):\n",
    "    doc.append(makeWordList(f))\n",
    "    index.append(0)\n",
    "for f in glob.glob('./email-data/spam/*.txt'):\n",
    "    doc.append(makeWordList(f))\n",
    "    index.append(1)\n",
    "index=np.array(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the document matrix `X` as a matrix of word frequencies [5 points]\n",
    "\n",
    "   - Use the `CountVectorizer` from scikit-learn.\n",
    "   - Set `min_df=50`; this drops words that don't occur in at least 50 documents.\n",
    "   - Set `stop_words=\"english\"` and `max_df=0.8` to filter out stop-words.\n",
    "   - Print the size of the vocabulary (number of unique words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=50, max_df=0.8)\n",
    "X = vectorizer.fit_transform(doc).toarray()\n",
    "list = vectorizer.get_feature_names()\n",
    "print(len(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN, SVM, random forest: Hyperparameter selection [15 points]\n",
    "\n",
    "Now that you have your documents and labels as training data, you can perform 5-fold cross-validation to select the hyperparameters for different learning algorithms.\n",
    "\n",
    "The hyperparameter with the best performance averaged across 5 folds is chosen. Use the **weighted F1-score** as the evaluation metric.\n",
    "\n",
    "   - k-NN: Select `k` from a range of values of your choice.\n",
    "   - SVM: (SVC) Select `C` from a range of your choice, use any kernel that performs well.\n",
    "   - Random forest: Select `n_estimators` **and** `max_depth` from a grid of your choice.\n",
    "\n",
    "Store each chosen hyperparameter as `best_k`, `best_alpha` and `best_C` respectively.\n",
    "\n",
    "Provided is some seed code for cross-validation that you may modify and reuse. Do not use the cross-validations score or grid-search functions from scikit-learn (you may use `KFold`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds)\n",
    "param_values = np.logspace(-4, 2, 3)\n",
    "\n",
    "arg_max = None\n",
    "fold_scores = []\n",
    "max_cross_val_score = -np.inf\n",
    "for C in param_values:\n",
    "    # your code to train and score the training data here\n",
    "    for train, val in k_fold.split(X,index):\n",
    "        clf = svm.SVC(kernel='rbf', C=C)\n",
    "        clf.fit(X[train],index[train])\n",
    "        ypred = clf.predict(X[val])\n",
    "        yval = index[val]\n",
    "        accuracy = f1_score(yval, ypred, average='weighted') \n",
    "        fold_scores.append(accuracy)        \n",
    "    cross_val_score = np.mean(fold_scores)\n",
    "    if cross_val_score > max_cross_val_score:\n",
    "        max_cross_val_score = cross_val_score\n",
    "        arg_max = C\n",
    "            \n",
    "best_C = arg_max\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X,index)\n",
    "predicted_train_labels = classifier.predict(X)\n",
    "error_rate = np.mean(predicted_train_labels != index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "num_train_images = len(X)\n",
    "shuffled_indices = np.random.permutation(num_train_images)\n",
    "\n",
    "train_frac = 0.7\n",
    "smaller_train_indices = shuffled_indices[:int(train_frac*num_train_images)]\n",
    "validation_indices = shuffled_indices[int(train_frac*num_train_images):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 1\n"
     ]
    }
   ],
   "source": [
    "lowest_error = np.inf\n",
    "best_k = None\n",
    "for k in range(1, 50):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(X[smaller_train_indices],\n",
    "                   index[smaller_train_indices])\n",
    "    predicted_val_labels = classifier.predict(X[validation_indices])\n",
    "    error = np.mean(predicted_val_labels != index[validation_indices])\n",
    "    if error < lowest_error:\n",
    "        lowest_error = error\n",
    "        best_k = k\n",
    "\n",
    "print('Best k:', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds)\n",
    "arg_max = 0\n",
    "fold_scores = []\n",
    "max_cross_val_score = 0\n",
    "for C in range(1,50):\n",
    "    # your code to train and score the training data here\n",
    "    for train, val in k_fold.split(X,index):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "        classifier.fit(X[smaller_train_indices],\n",
    "                   index[smaller_train_indices])\n",
    "        predicted_val_labels = classifier.predict(X[validation_indices])\n",
    "        yval = index[val]\n",
    "        accuracy = f1_score(yval, predicted_val_labels, average='weighted') \n",
    "        fold_scores.append(accuracy)        \n",
    "    cross_val_score = np.mean(fold_scores)\n",
    "    if cross_val_score > max_cross_val_score:\n",
    "        max_cross_val_score = cross_val_score\n",
    "        arg_max = C\n",
    "            \n",
    "best_K = arg_max\n",
    "print(best_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00019338619222587506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=0)  # n_estimators is the number of trees\n",
    "rf_classifier.fit(X,index)\n",
    "rf_predicted_train_labels = rf_classifier.predict(X)\n",
    "rf_error = np.mean(rf_predicted_train_labels != index)\n",
    "print(rf_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier testing: Precision-Recall and ROC curves [20 points]\n",
    "\n",
    "   - Use the best hyperparameters for each classifier from the previous question to **train** your classifiers on the training data.\n",
    "   - Use test emails to in the `testing` folder to **test** your classifiers and construct the plots below.\n",
    "\n",
    "Things to plot:\n",
    "\n",
    "   - Construct one plot containing 3 ROC curves, one for each classifier.\n",
    "   - In the legend of this plot, display the AUC for each classifier.\n",
    "   - Construct one plot containing 3 precision-recall curves, one for each classifier.\n",
    "   - In the legend of each plot, display the average precision for each classifier.\n",
    "\n",
    "Note that these plots are on the test data: you will have to read in this data, construct a document matrix and labels. Some words in the test data may not have been present in the training data: there are multiple ways to address this, briefly describe your approach.\n",
    "\n",
    "Things to answer:\n",
    "\n",
    "   - Of the ROC and Precision-Recall curves, which one would you use for this task and why?\n",
    "   - Which classifier is the best, according to your chosen curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Image Segmentation [50 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is segmentation?\n",
    "\n",
    "Segmentation is the task of \"labeling\" groups of pixels in an image to identify certain objects.\n",
    "\n",
    "In the early years, research on segmentation was focused on \"foreground-background\" segmentation; marking only those pixels that comprise the \"background\" of an image (in the image below, the background is marked in blue).\n",
    "\n",
    "<div>\n",
    "<img src=\"http://www.eyeshalfclosed.com/images/cat.jpg\" width=500/>\n",
    "</div>\n",
    "\n",
    "In recent years, sophisticated deep-learning models have enabled complex multi-label segmentation, such as in the images below.\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"http://www.eyeshalfclosed.com/images/sheep.png\" width=500/>\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"http://www.eyeshalfclosed.com/images/street.png\" width=500/>\n",
    "</td>\n",
    "</tr>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites [20 points]\n",
    "\n",
    "You get 20 points for setting up AWS and successfully running the code given in the following sections.\n",
    "\n",
    "This homework needs to be run on an AWS GPU instance; it will not complete in time without a GPU. Look up the relevant documentation to set up an AWS machine as configured below.\n",
    "\n",
    "**Machine.**\n",
    "\n",
    "   - Use the [Ubuntu Deep Learning AMI](https://aws.amazon.com/marketplace/pp/B077GCH38C).\n",
    "   - Use a p2.xlarge instance.\n",
    "   - Allocate at least 80GB of disk space.\n",
    "   - Use the `conda_tensorflow_p36` Conda environment: `source activate tensorflow_p36`\n",
    "   - Create a security group and open all inbound/outbound ports to 0.0.0.0/0.\n",
    "\n",
    "All commands below assume the aforementioned Conda environment is active.\n",
    "\n",
    "**Run Jupyter.** `jupyter notebook --ip=* --no-browser`\n",
    "\n",
    "You may move Jupyter to the background by: CTRL-Z, then `bg`, then `disown`. You can access Jupyter using your public DNS; it will look something like `ec2-54-84-36-171.compute-1.amazonaws.com:8888`. Figure out how you can find this out.\n",
    "\n",
    "**Data downloads.** All downloads must go into the same directory as this notebook. Unzip files after download. *This will take time.*\n",
    "\n",
    "   * Download the [trained model weights](https://github.com/matterport/Mask_RCNN/releases/download/v1.0/mask_rcnn_coco.h5) (~250MB).\n",
    "\n",
    "   * Download the [training images](http://images.cocodataset.org/zips/train2014.zip) (13GB).\n",
    "   \n",
    "   * Download the [validation images](http://images.cocodataset.org/zips/val2014.zip) (6GB).\n",
    "   * Download the [training image annotations](https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0).\n",
    "   * Download the [test image annotations](https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0).\n",
    "\n",
    "Now create a new folder named `2014`, then move the `train2014`, `val2014` folders into `2014/`.\n",
    "\n",
    "Create a new `2014/annotations/` folder and move the train and test annotation JSON files into it\n",
    "\n",
    "Your directory structure should look like:\n",
    "```\n",
    "2014/\n",
    "   /annotations/\n",
    "       /annotations/instances_minival2014.json\n",
    "       /annotations/instances_valminusminival2014.json\n",
    "   /train2014/\n",
    "       /train2014/*.jpg\n",
    "   /val2014/\n",
    "       /val2014/*.jpg\n",
    "```\n",
    "\n",
    "**Package installation.**\n",
    "\n",
    "   * Install Cython: `pip install cython`\n",
    "   * Install Tensorflow: `pip install tensorflow==1.3.0 tensorflow-gpu==1.3.0`\n",
    "   * Install Keras and image tools: `pip install keras scikit-image pillow h5py`\n",
    "   * Install OpenCV: `pip install opencv-python`\n",
    "   * Install pycoco:\n",
    "   \n",
    "`pip install \"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\"`\n",
    "   \n",
    "**GPU.** Ensure Keras/TensorFlow can see your GPU with the following Python code (run in the `conda_tensorflow_p36 environment` after installing all the required packages). You should see a GPU in one of the devices listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a pre-trained model on small data\n",
    "\n",
    "We will first load a pre-trained convolutional neural network model and test it on a small dataset of images. These images are stored in the `/images/` folder.\n",
    "\n",
    "The model was trained by annotating each image with the objects it contains. Annotations are in the following format:\n",
    "\n",
    "```\n",
    "annotation{\n",
    "    \"id\" : int,\n",
    "    \"image_id\" : int,\n",
    "    \"category_id\" : int,\n",
    "    \"segmentation\" : RLE or [polygon],\n",
    "    \"area\" : float,\n",
    "    \"bbox\" : [x,y,width,height],\n",
    "    \"iscrowd\" : 0 or 1,\n",
    "}\n",
    "\n",
    "categories[{\n",
    "    \"id\" : int,\n",
    "    \"name\" : str,\n",
    "    \"supercategory\" : str,\n",
    "}]\n",
    "```\n",
    "\n",
    "Make sure you understand the annotations and how they are connect to images by looking at [section 4 on this page](http://cocodataset.org/#download). You may ignore the `iscrowd` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "from model import log\n",
    "import visualize\n",
    "from config import Config\n",
    "from shapes import ShapesDataset\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration\n",
    "\n",
    "These lines specify how many GPUs to use, and how many images to process in parallel on each GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "#config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained model\n",
    "\n",
    "This is actually a Keras model wrapped along with some helpful functions. The model may be loaded in two modes: `training` and `inference` (testing) mode. `model_dir` points towards a directory to save logs and trained weights, which we have set above as the `/logs` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard-code object classes\n",
    "\n",
    "For the small dataset of images we are using, we define our own list of class names and class indices for each object. These are of various types: for example, \"car\", \"bicycle\", etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize a random image\n",
    "\n",
    "Make sure you understand what the code below is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the pre-trained model\n",
    "\n",
    "We now call the `detect` function of the model on the list of images we want to be segmented. This returns a `result` object; inspect this object to see what it contains.\n",
    "\n",
    "The `visualize` helper module provides useful functions to visualize our segmentation results. Understand how this function works (SHIFT+TAB in Jupyter is useful, as well as looking at the code in `visualize.py` directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = model.detect([image], verbose=1)\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training from scratch\n",
    "\n",
    "Now that we understand what a properly trained model should do, we consider training a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "Load the annotations for the training images into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "config = coco.CocoConfig()\n",
    "COCO_DIR = \"2014\"\n",
    "dataset = coco.CocoDataset()\n",
    "dataset.load_coco(COCO_DIR, \"minival\")\n",
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the same for the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_val = coco.CocoDataset()\n",
    "dataset_val.load_coco(COCO_DIR, \"val35k\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List a few object classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
    "print(\"Class Count: {}\".format(dataset.num_classes))\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a random image and its annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load random image and mask.\n",
    "image_id = random.choice(dataset.image_ids)\n",
    "image = dataset.load_image(image_id)\n",
    "mask, class_ids = dataset.load_mask(image_id)\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "# Display image and additional stats\n",
    "print(\"image_id \", image_id, dataset.image_reference(image_id))\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "\n",
    "# Display image and instances\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training configuration\n",
    "\n",
    "See the default configuration values in `config.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    STEPS_PER_EPOCH = 60\n",
    "\n",
    "config = TrainConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new model in training mode [5 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model in training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model weights with the weights learned on COCO [5 points]\n",
    "\n",
    "Call `load_weights` as before, but add the following argument in the call to the function:\n",
    "\n",
    "```\n",
    "exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "          \"mrcnn_bbox\", \"mrcnn_mask\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model for 10 epochs [5 points]\n",
    "\n",
    "Look up the documentation or code for the train function to figure out its arguments.\n",
    "\n",
    "Pass the following additional arguments to the `train` function:\n",
    "\n",
    "   - `layers=\"heads\"` to only train the weights that were not pre-loaded.\n",
    "   - `learning_rate=config.LEARNING_RATE` to set the learning rate.\n",
    "   - `epochs=10`.\n",
    "   \n",
    "This will take ~10 minutes on a p2.xlarge GPU instance with 1 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# call to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize learning progress with TensorBoard [5 points]\n",
    "\n",
    "   - Start Tensorboard with `tensorboard --logdir=logs/` in the same folder as the notebook:\n",
    "```\n",
    "TensorBoard 0.1.8 at http://ip-172-31-27-18:6006 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "   - Connect to `public_dns:6006` where `public_dns` is your public DNS.\n",
    "   - Click on the \"Scalars\" tab at the top of the page.\n",
    "   - Include a screenshot of the overall loss vs. number of epochs below this line (store the image in the same folder as the notebook as \"yourloss.png\".\n",
    "   \n",
    " <img src=\"yourloss.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model in inference (testing) mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the last trained model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = model.find_last()[1] # use the last trained weights\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the true annotations of a random test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_bbox)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the predicted annotations for this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction function call and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Sentiment Analysis [50 points]\n",
    "\n",
    "Download data from: https://www.dropbox.com/s/ouhiwmzodc4baob/HW3-data-Sentiment.zip?dl=0 <br>\n",
    "\n",
    "The folder contains:\n",
    "\n",
    "- Train.csv\n",
    "- test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the training data  [5 Points]\n",
    "\n",
    "Read the data present in training.csv file. **Please do no change the file name and use relative path, i.e. './HW3-data/train.csv'** <br>\n",
    "Perform the following cleaning on the data:\n",
    "1. Keep only the Sentiment and sentiment text in the dataframe - the first and the last coumn\n",
    "2. Some of the sentiments and sentiment texts are empty. Remove those rows.\n",
    "3. Shuffle the rows of the data frame such that the positive and negative tweets are mixed\n",
    "4. Print the first 5 sentiments.\n",
    "5. Print the number of positive and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import pandas as pd\n",
    "dataOriginal = pd.read_csv('./HW3-data/train.csv',encoding = 'iso-8859-1')\n",
    "dataOriginal.columns=['A','B','C','D','E','F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOriginal.drop(['B','C','D','E'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>I just re-pierced my ears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>@octolinz16 It it counts, idk why I did either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>@smarrison i would've been the first, but i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>@iamjazzyfizzle I wish I got to watch it with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>Hollis' death scene will hurt me severely to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>about to file taxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>@LettyA ahh ive always wanted to see rent  lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>@FakerPattyPattz Oh dear. Were you drinking ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>@alydesigns i was out most of the day so didn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>one of my friend called me, and asked to meet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>@angry_barista I baked you a cake but I ated it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>this week is not going as i had hoped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>blagh class at 8 tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>I hate when I have to call and wake people up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>Just going to cry myself to sleep after watchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>im sad now  Miss.Lilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>ooooh.... LOL  that leslie.... and ok I won't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>Meh... Almost Lover is the exception... this t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>some1 hacked my account on aim  now i have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599969</th>\n",
       "      <td>1</td>\n",
       "      <td>Thanks @eastwestchic &amp;amp; @wangyip Thanks! Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599970</th>\n",
       "      <td>1</td>\n",
       "      <td>@marttn thanks Martin. not the most imaginativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599971</th>\n",
       "      <td>1</td>\n",
       "      <td>@MikeJonesPhoto Congrats Mike  Way to go!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599972</th>\n",
       "      <td>1</td>\n",
       "      <td>http://twitpic.com/7jp4n - OMG! Office Space.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599973</th>\n",
       "      <td>1</td>\n",
       "      <td>@yrclndstnlvr ahaha nooo you were just away fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599974</th>\n",
       "      <td>1</td>\n",
       "      <td>@BizCoachDeb  Hey, I'm baack! And, thanks so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599975</th>\n",
       "      <td>1</td>\n",
       "      <td>@mattycus Yeah, my conscience would be clear i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599976</th>\n",
       "      <td>1</td>\n",
       "      <td>@MayorDorisWolfe Thats my girl - dishing out t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599977</th>\n",
       "      <td>1</td>\n",
       "      <td>@shebbs123 i second that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599978</th>\n",
       "      <td>1</td>\n",
       "      <td>In the garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599979</th>\n",
       "      <td>1</td>\n",
       "      <td>@myheartandmind jo jen by nemuselo zrovna tÃ© ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599980</th>\n",
       "      <td>1</td>\n",
       "      <td>Another Commenting Contest! [;: Yay!!!  http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599981</th>\n",
       "      <td>1</td>\n",
       "      <td>@thrillmesoon i figured out how to see my twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599982</th>\n",
       "      <td>1</td>\n",
       "      <td>@oxhot theri tomorrow, drinking coffee, talkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599983</th>\n",
       "      <td>1</td>\n",
       "      <td>You heard it here first -- We're having a girl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599984</th>\n",
       "      <td>1</td>\n",
       "      <td>if ur the lead singer in a band, beware fallin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599985</th>\n",
       "      <td>1</td>\n",
       "      <td>@tarayqueen too much ads on my blog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599986</th>\n",
       "      <td>1</td>\n",
       "      <td>@La_r_a NEVEER  I think that you both will get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599987</th>\n",
       "      <td>1</td>\n",
       "      <td>@Roy_Everitt ha- good job. that's right - we g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599988</th>\n",
       "      <td>1</td>\n",
       "      <td>@Ms_Hip_Hop im glad ur doing well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599989</th>\n",
       "      <td>1</td>\n",
       "      <td>WOOOOO! Xbox is back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599990</th>\n",
       "      <td>1</td>\n",
       "      <td>@rmedina @LaTati Mmmm  That sounds absolutely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599991</th>\n",
       "      <td>1</td>\n",
       "      <td>ReCoVeRiNg FrOm ThE lOnG wEeKeNd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599992</th>\n",
       "      <td>1</td>\n",
       "      <td>@SCOOBY_GRITBOYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599993</th>\n",
       "      <td>1</td>\n",
       "      <td>@Cliff_Forster Yeah, that does work better tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>1</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A                                                  F\n",
       "0        0  is upset that he can't update his Facebook by ...\n",
       "1        0  @Kenichan I dived many times for the ball. Man...\n",
       "2        0    my whole body feels itchy and like its on fire \n",
       "3        0  @nationwideclass no, it's not behaving at all....\n",
       "4        0                      @Kwesidei not the whole crew \n",
       "5        0                                        Need a hug \n",
       "6        0  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "7        0               @Tatiana_K nope they didn't have it \n",
       "8        0                          @twittera que me muera ? \n",
       "9        0        spring break in plain city... it's snowing \n",
       "10       0                         I just re-pierced my ears \n",
       "11       0  @caregiving I couldn't bear to watch it.  And ...\n",
       "12       0  @octolinz16 It it counts, idk why I did either...\n",
       "13       0  @smarrison i would've been the first, but i di...\n",
       "14       0  @iamjazzyfizzle I wish I got to watch it with ...\n",
       "15       0  Hollis' death scene will hurt me severely to w...\n",
       "16       0                               about to file taxes \n",
       "17       0  @LettyA ahh ive always wanted to see rent  lov...\n",
       "18       0  @FakerPattyPattz Oh dear. Were you drinking ou...\n",
       "19       0  @alydesigns i was out most of the day so didn'...\n",
       "20       0  one of my friend called me, and asked to meet ...\n",
       "21       0   @angry_barista I baked you a cake but I ated it \n",
       "22       0             this week is not going as i had hoped \n",
       "23       0                         blagh class at 8 tomorrow \n",
       "24       0     I hate when I have to call and wake people up \n",
       "25       0  Just going to cry myself to sleep after watchi...\n",
       "26       0                             im sad now  Miss.Lilly\n",
       "27       0  ooooh.... LOL  that leslie.... and ok I won't ...\n",
       "28       0  Meh... Almost Lover is the exception... this t...\n",
       "29       0  some1 hacked my account on aim  now i have to ...\n",
       "...     ..                                                ...\n",
       "1599969  1  Thanks @eastwestchic &amp; @wangyip Thanks! Th...\n",
       "1599970  1  @marttn thanks Martin. not the most imaginativ...\n",
       "1599971  1          @MikeJonesPhoto Congrats Mike  Way to go!\n",
       "1599972  1  http://twitpic.com/7jp4n - OMG! Office Space.....\n",
       "1599973  1  @yrclndstnlvr ahaha nooo you were just away fr...\n",
       "1599974  1  @BizCoachDeb  Hey, I'm baack! And, thanks so m...\n",
       "1599975  1  @mattycus Yeah, my conscience would be clear i...\n",
       "1599976  1  @MayorDorisWolfe Thats my girl - dishing out t...\n",
       "1599977  1                          @shebbs123 i second that \n",
       "1599978  1                                     In the garden \n",
       "1599979  1  @myheartandmind jo jen by nemuselo zrovna tÃ© ...\n",
       "1599980  1  Another Commenting Contest! [;: Yay!!!  http:/...\n",
       "1599981  1  @thrillmesoon i figured out how to see my twee...\n",
       "1599982  1  @oxhot theri tomorrow, drinking coffee, talkin...\n",
       "1599983  1  You heard it here first -- We're having a girl...\n",
       "1599984  1  if ur the lead singer in a band, beware fallin...\n",
       "1599985  1              @tarayqueen too much ads on my blog. \n",
       "1599986  1  @La_r_a NEVEER  I think that you both will get...\n",
       "1599987  1  @Roy_Everitt ha- good job. that's right - we g...\n",
       "1599988  1                 @Ms_Hip_Hop im glad ur doing well \n",
       "1599989  1                              WOOOOO! Xbox is back \n",
       "1599990  1  @rmedina @LaTati Mmmm  That sounds absolutely ...\n",
       "1599991  1                  ReCoVeRiNg FrOm ThE lOnG wEeKeNd \n",
       "1599992  1                                  @SCOOBY_GRITBOYS \n",
       "1599993  1  @Cliff_Forster Yeah, that does work better tha...\n",
       "1599994  1  Just woke up. Having no school is the best fee...\n",
       "1599995  1  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599996  1  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599997  1  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599998  1  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1599999 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataOriginal.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "dataNeed = shuffle(dataOriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A                                                  F\n",
      "346432   0  The Internet's definitely messed up when you c...\n",
      "45733    0  is wondering if there's any hope for freshers ...\n",
      "1076938  1  videomatica - I *heart* you.  Thank you for ha...\n",
      "1526985  1  i just want to hang out and have fun!!   -Lets...\n",
      "1512546  1  @the_RSN I miss you too RALPH-pogi! HAHA. Aw I...\n"
     ]
    }
   ],
   "source": [
    "print(dataNeed.iloc[:][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive sentiments numbers: 800000\n",
      "negative sentiments numbers: 799999\n"
     ]
    }
   ],
   "source": [
    "countN = 0\n",
    "countP = 0\n",
    "dataState = dataNeed.iloc[:,0]\n",
    "arrs = dataState.values\n",
    "for i in arrs:\n",
    "    if(i == 0):\n",
    "        countN +=1\n",
    "    if(i == 1):\n",
    "        countP +=1\n",
    "print(\"positive sentiments numbers:\", countP)\n",
    "print(\"negative sentiments numbers:\", countN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building a neural network model, we first need to prepare the data. The input to a RNN model  is a matrix with shape (a, b), where a is the number of samples (twitters), and b is the sequence length of each tweet. Prepare the data with the following steps:\n",
    "\n",
    "1\\. Take the RAW texts of the top 5000 tweets in the dataframe, and convert them to a list of strings, where each string is a tweet. [1 pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "rawFrame = dataNeed.iloc[:5000,1:2]\n",
    "train_data = np.array(rawFrame)\n",
    "train_list = train_data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Use `Tokenizer` from `keras.preprocessing.text` to tokenize the texts and convert them to sequences (numbers) with `texts_to_sequences` method of `Tokenizer`. **When tokenizing, please only consider the top 10,000 words in the dataset (`num_words`=10,000)**. [4 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_list)\n",
    "sequences = tokenizer.texts_to_sequences(train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Use `pad_sequences` from `keras.preprocessing.sequence` to pad each sequence with zeros to **make the sequence length 120**. [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padding_sequence = pad_sequences(sequences,maxlen=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Split the above data (the sequence and the label) into training (67%) and validation (33%) sets. [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "array_label = np.array(dataState)\n",
    "list_label = array_label.tolist()\n",
    "label = []\n",
    "indices = np.arange(padding_sequence.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "padding_sequence = padding_sequence[indices]\n",
    "for i in indices:\n",
    "    label.append(list_label[i])\n",
    "validation = int(0.33*padding_sequence.shape[0])\n",
    "x_train = padding_sequence[:-validation]\n",
    "y_train = label[:-validation]\n",
    "x_test = padding_sequence[-validation:]\n",
    "y_test = label[-validation:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  RNN [20 points]\n",
    "\n",
    "i) [8 points] Build a simple RNN model with the following specification:\n",
    "1. An embedding layer with output dimenstion 64.\n",
    "2. A simple RNN layer.\n",
    "3. A dense layer with sigmoid activation function for prediction.\n",
    "Print the summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 120, 64)           640000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                245792    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 885,825\n",
      "Trainable params: 885,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "max_words = 10000\n",
    "embedding_dim = 64\n",
    "# initialize the model\n",
    "feedforward_model = Sequential()\n",
    "# add the embedding layer; it takes 3 arguments: the total number of words (10000), \n",
    "# embedding dimension(100), and the input length (100)--the last argument is required \n",
    "# as we are going to connect Flatten then Dense layers (without it, the shape of\n",
    "# the dense outputs cannot be computed).\n",
    "feedforward_model.add(Embedding(max_words, embedding_dim, input_length=120))\n",
    "# then flatten the 3D tensor into a 2D matrix as the input for the subsequent layer\n",
    "feedforward_model.add(Flatten())\n",
    "# add a dense layer with 32 nodes\n",
    "feedforward_model.add(Dense(32, activation='relu'))\n",
    "# add a logistic regression binary classifier\n",
    "feedforward_model.add(Dense(1, activation='sigmoid'))\n",
    "feedforward_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) [12 points] Now train the simple RNN model:\n",
    "\n",
    "1\\. Compile the model with binary cross entory as loss and accuracy as evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# compile and train the model\n",
    "feedforward_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Fit the model with the training set with 5 epochs and batch size 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2680 samples, validate on 670 samples\n",
      "Epoch 1/5\n",
      "2680/2680 [==============================] - 3s 1ms/step - loss: 0.6966 - acc: 0.5015 - val_loss: 0.6931 - val_acc: 0.5030\n",
      "Epoch 2/5\n",
      "2680/2680 [==============================] - 0s 137us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5030\n",
      "Epoch 3/5\n",
      "2680/2680 [==============================] - 0s 138us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5030\n",
      "Epoch 4/5\n",
      "2680/2680 [==============================] - 0s 137us/step - loss: 0.6932 - acc: 0.4896 - val_loss: 0.6931 - val_acc: 0.5030\n",
      "Epoch 5/5\n",
      "2680/2680 [==============================] - 0s 137us/step - loss: 0.6932 - acc: 0.4754 - val_loss: 0.6931 - val_acc: 0.4970\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "history = feedforward_model.fit(x_train, y_train,\n",
    "                                validation_split=0.2,\n",
    "                                epochs=5,\n",
    "                                batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Plot the training and validation accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f35d6f7d4e0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "# plot the accuracy rates for each epoch on training and validation data\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM [10 points] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) [2 point] Now built a LSTM model by replacing the simple RNN layter in the above model with a LSTM layer. Print a summary of the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 64)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 673,089\n",
      "Trainable params: 33,089\n",
      "Non-trainable params: 640,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(max_words, embedding_dim))\n",
    "rnn_model.add(LSTM(embedding_dim))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "rnn_model.layers[0].trainable = False\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) [2 point] Train the LSTM model with the same specifications in the simple RNN model. Again, plot the training and validation accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2680 samples, validate on 670 samples\n",
      "Epoch 1/5\n",
      "2680/2680 [==============================] - 15s 6ms/step - loss: 0.6939 - acc: 0.4959 - val_loss: 0.6932 - val_acc: 0.4806\n",
      "Epoch 2/5\n",
      "2680/2680 [==============================] - 13s 5ms/step - loss: 0.6931 - acc: 0.5164 - val_loss: 0.6932 - val_acc: 0.4881\n",
      "Epoch 3/5\n",
      "2680/2680 [==============================] - 13s 5ms/step - loss: 0.6933 - acc: 0.5045 - val_loss: 0.6932 - val_acc: 0.5045\n",
      "Epoch 4/5\n",
      "2680/2680 [==============================] - 14s 5ms/step - loss: 0.6929 - acc: 0.4951 - val_loss: 0.6933 - val_acc: 0.4985\n",
      "Epoch 5/5\n",
      "2680/2680 [==============================] - 13s 5ms/step - loss: 0.6926 - acc: 0.5060 - val_loss: 0.6932 - val_acc: 0.5030\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "rnn_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = rnn_model.fit(x_train, y_train,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=5,\n",
    "                        batch_size=32)\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) [6 points] In the previous models, we only use the top 5000 tweets. Now use the whole dataset, split it into training (67%) and validation (33%) set, and train the same LSTM model on the new traning data. plot the training and validation accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(max_words, embedding_dim))\n",
    "rnn_model.add(LSTM(embedding_dim))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "rnn_model.summary()\n",
    "\n",
    "rnn_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = rnn_model.fit(x_train, y_train,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=5,\n",
    "                        batch_size=1024) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Comparision [5 points]\n",
    "\n",
    "1\\. [2 points] Compare the simple RNN model and the LSTM model (trained on the 5000 tweets sample). Which one has a better performance? Why does this one outperform the other one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. [3 points] Compare the LSTM model trained on a 5000 tweets sample and the one trained on the whole dataset. What are the cost and the benefit of each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Questionnaire [5 points]\n",
    "\n",
    "Please answer this questionnaire: https://goo.gl/forms/eN6pUx6QPIg2K9w13"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
